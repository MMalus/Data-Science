{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a personal modification of a tutorial found at\n",
    "\n",
    "https://machinelearningmastery.com/regression-tutorial-keras-deep-learning-library-python/\n",
    "\n",
    "The problems with the above tutorial are manifold, but the most glaring issue is that the data is not properly segregated before building/training the model.  This is actually a consistent issue I've seen with such tutorials, and it seriously impacts the expected results of a given technique.  Additionally, I explore some slightly more aggressive implementations of NN topology than the author does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usual imports to set up the full background\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For reproducibility, always set the random seed\n",
    "seed = 0\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296.0   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242.0   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242.0   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222.0   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Unfortunately the dataset does not come in csv format and we have to manually input the column names\n",
    "col_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "df = pd.read_csv(r\"J:\\CASHDESK\\Malus\\Housing DL\\housing.csv\", delim_whitespace = True, header = None, names = col_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate out data and target\n",
    "X = df.iloc[:,0:13]\n",
    "y = df.iloc[:, 13]\n",
    "#And then split into a training and hold out test set.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a baseline model, this will be the same as the initial model used by the tutorial.  But in order to better make\n",
    "#use of the pipeline and transformer below, I'm going to structure it differently.\n",
    "\n",
    "def basic_model():\n",
    "    basic_model = Sequential()\n",
    "    basic_model.add(Dense(13, input_dim = 13, kernel_initializer = 'normal', activation = 'relu'))\n",
    "    basic_model.add(Dense(1, kernel_initializer = 'normal'))\n",
    "    basic_model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "    return basic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized: 0.15 (0.09) MSE\n"
     ]
    }
   ],
   "source": [
    "#A key point that the tutorial misses is data leakage, ensuring that future information does not impact present\n",
    "#information.  The pipeline will support this, but it needs a different setup than the naive \"throw everything in\"\n",
    "#method of the tutorial.\n",
    "\n",
    "X_scaler = StandardScaler()\n",
    "X_train_scaled = X_scaler.fit_transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y_train_scaled = y_scaler.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_test_scaled = y_scaler.transform(y_test.values.reshape(-1, 1))\n",
    "\n",
    "estimators = []\n",
    "#estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn = basic_model, epochs = 50, batch_size = 5, verbose = 0)))\n",
    "\n",
    "#Now we can actually standardize it properly for our case.\n",
    "\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits = 10, random_state = seed)\n",
    "results = cross_val_score(pipeline, X_train_scaled, y_train_scaled, cv = kfold)\n",
    "\n",
    "#Note here that I am flipping the sign of the MSE, it normally outputs a negative number to account for the \n",
    "#\"greater is better\" aspect programmed into the cross_val_score() function\n",
    "\n",
    "print(\"Standardized: %.2f (%.2f) MSE\" % (np.abs(results.mean()), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2803054942089024"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now this has to be generalized to the actual unseen data.\n",
    "pipeline.fit(X_train_scaled, y_train_scaled)\n",
    "prediction = pipeline.predict(X_test_scaled)\n",
    "mse(y_test_scaled, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#While it is worth it to explore deeper networks, a word of caution: given how little data we have, we must be\n",
    "#very wary of overfitting.\n",
    "\n",
    "def expanded_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13, input_dim = 13, kernel_initializer = 'normal', activation = 'relu'))\n",
    "    model.add(Dense(6, kernel_initializer = 'normal', activation = 'relu'))\n",
    "    model.add(Dense(1, kernel_initializer = 'normal'))\n",
    "    model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized: 0.16 (0.12) MSE\n"
     ]
    }
   ],
   "source": [
    "#Same idea as before\n",
    "estimators = []\n",
    "estimators.append(('mlp', KerasRegressor(build_fn = expanded_model, epochs = 50, batch_size = 5, verbose = 0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits = 10, random_state = seed)\n",
    "results = cross_val_score(pipeline, X_train_scaled, y_train_scaled, cv = kfold)\n",
    "print(\"Standardized: %.2f (%.2f) MSE\" % (np.abs(results.mean()), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2420705111345385"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Not a real improvement on the training/validation sets, but we can see a solid improvement in the test set below\n",
    "pipeline.fit(X_train_scaled, y_train_scaled)\n",
    "prediction = pipeline.predict(X_test_scaled)\n",
    "mse(y_test_scaled, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A wider network is another possibility\n",
    "def wide_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim = 13, kernel_initializer = 'normal', activation = 'relu'))\n",
    "    model.add(Dense(1, kernel_initializer = 'normal'))\n",
    "    #Compile the model\n",
    "    model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized: 0.15 (0.13) MSE\n"
     ]
    }
   ],
   "source": [
    "#Proceeding as before\n",
    "estimators = []\n",
    "estimators.append(('mlp', KerasRegressor(build_fn = wide_model, epochs = 50, batch_size = 5, verbose = 0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits = 10, random_state = seed)\n",
    "results = cross_val_score(pipeline, X_train_scaled, y_train_scaled, cv = kfold)\n",
    "print(\"Standardized: %.2f (%.2f) MSE\" % (np.abs(results.mean()), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26079632272756487"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Not a real improvement on the training/validation sets, but we can see a solid improvement in the test set below\n",
    "pipeline.fit(X_train_scaled, y_train_scaled)\n",
    "prediction = pipeline.predict(X_test_scaled)\n",
    "mse(y_test_scaled, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The final option would be to combine both varieties of model to create a deep and wide model as follows\n",
    "def deep_wide_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim = 13, kernel_initializer = 'normal', activation = 'relu'))\n",
    "    model.add(Dense(10, kernel_initializer = 'normal', activation = 'relu'))\n",
    "    model.add(Dense(10, kernel_initializer = 'normal', activation = 'relu'))\n",
    "    model.add(Dense(1, kernel_initializer = 'normal'))\n",
    "    #Compile the model\n",
    "    model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized: 0.14 (0.12) MSE\n"
     ]
    }
   ],
   "source": [
    "#Proceeding as before\n",
    "estimators = []\n",
    "estimators.append(('mlp', KerasRegressor(build_fn = deep_wide_model, epochs = 50, batch_size = 5, verbose = 0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits = 10, random_state = seed)\n",
    "results = cross_val_score(pipeline, X_train_scaled, y_train_scaled, cv = kfold)\n",
    "print(\"Standardized: %.2f (%.2f) MSE\" % (np.abs(results.mean()), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21501132988032934"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#So some training/validation data improvement.  Finally, we see our best result below by having combined methods.\n",
    "pipeline.fit(X_train_scaled, y_train_scaled)\n",
    "prediction = pipeline.predict(X_test_scaled)\n",
    "mse(y_test_scaled, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
